{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classification using multiple classifiers\n",
    "Team Members: Lisa Korntheuer, Jan Birkert, Adrian Desiderato, Jan Wangerin, Spyridon Spyropoulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data understanding\n",
    "Data describe (Features, Target etc.)\n",
    "- filename and length irrelevant for ML\n",
    "- 57 features -> PCA?\n",
    "- only numerical data except for class labels (\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/features_30_sec.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations between features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = df.iloc[:, 2:-2].corr()\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "ax = sns.heatmap(cor, square = True, xticklabels=True, yticklabels=True) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are quite a few feature combinations with high correlations, PCA may be worth a try. (See Data Prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "Jan W.\n",
    "\n",
    "Data splitting\n",
    "\n",
    "y = LabelEncoder() \n",
    "\n",
    "MinMax()\n",
    "Das andere() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelEnc = LabelEncoder()\n",
    "y = df['label']\n",
    "y = pd.DataFrame(LabelEnc.fit_transform(y))\n",
    "df['label_enc'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_mms = MinMaxScaler()\n",
    "scaler_ss = StandardScaler()\n",
    "X = df.loc[:, 'chroma_stft_mean' : 'mfcc20_var']\n",
    "X_scaled_array_mms = scaler_mms.fit_transform(X)\n",
    "X_scaled_array_ss = scaler_ss.fit_transform(X)\n",
    "X_scaled_mms = pd.DataFrame(X_scaled_array_mms, columns=X.columns)\n",
    "X_scaled_ss = pd.DataFrame(X_scaled_array_ss, columns=X.columns)\n",
    "print(X)\n",
    "print(X_scaled_mms)\n",
    "print(X_scaled_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA: (copied from Material Notebook 04, probably has to be adjusted later on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA() # typically you add here as a parameter the nbr. of cmponents: i.e.: n_components=2\n",
    "            # we leave it blank to get all!\n",
    "pcs = pca.fit_transform(X_scaled_ss) # principle components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenvalues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pca.explained_variance_)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Components (Dot Product of Data and Eigenvectors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pcs[:5])\n",
    "print()\n",
    "print(len(pcs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scree Plot with Kaiser Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "pc_values = np.arange(pca.n_components_) + 1\n",
    "ax.plot(pc_values, pca.explained_variance_, 'o-', linewidth=2, color='blue')\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.axhline(y=1, linewidth=1, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potentially, a lot of dimensions could be removed according to the Kaiser criteria. The following enumeration shows how much \"information\" is contained in how many of the principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [10, 15, 30, 45]:\n",
    "    print(np.sum(pca.explained_variance_ratio_[:i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fight the curse of dimensionality, some dimensions could be removed, for example the last 12 to even 27 dimensions, since about 94% of \"information\" is contained in the first 30 PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "X_train_mms, X_test_mms, y_train_mms, y_test_mms = train_test_split(X_scaled_mms, y, test_size=0.2, random_state=0, stratify=y)\n",
    "X_train_ss, X_test_ss, y_train_ss, y_test_ss = train_test_split(X_scaled_ss, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model training \n",
    "\n",
    "Each Modell is trained and the quality of the classifier(accuracy) is displayed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Random Forests\n",
    "Spyridon \n",
    "\n",
    "In this section Random Forest as a classifier will be tested. In the first step all important libraries will be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.tree as tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training random forests, there is no heavy hyperparameter needed. The structure of the model is already decreasing Bias and Variance. So it is enough only to tune the numbers of trees in the ensemlbe \"n_estimators\" and the spliting criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "param_grid = {'n_estimators': np.array([ 100, 250, 500, 1000, 2000, 7000]), \n",
    "              'criterion':['gini','entropy', 'log_loss'],\n",
    "              }\n",
    "grid_search_rf = GridSearchCV(rf, param_grid, n_jobs=-1, cv=2, scoring='accuracy', verbose=3, refit=True)\n",
    "grid_search_rf.fit(X_train, y_train.values.ravel())\n",
    "#rf.fit(X_train, y_train.values.ravel())\n",
    "y_pred = grid_search_rf.predict(X_test)\n",
    "print(grid_search_rf.best_params_)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "grid_search_rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Decision trees\n",
    "\n",
    "Jan W.\n",
    "\n",
    "First try using post-pruning and the entire dataset. Post-pruning is done using hyperparameter-tuning with GridsearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn import tree\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0) #maybe use variable for random state so that all classifiers can be adjusted at the same time\n",
    "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ccp_alphas[:-1], impurities[:-1], marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax.set_xlabel(\"effective alpha\")\n",
    "ax.set_ylabel(\"total impurity of leaves\")\n",
    "ax.set_title(\"Total Impurity vs effective alpha for training set\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'ccp_alpha':ccp_alphas[:-1].tolist()}\n",
    "gs = GridSearchCV(DecisionTreeClassifier(random_state=0), parameters, cv=10, refit=True)\n",
    "gs.fit(X_train,y_train)\n",
    "tree_best = gs.best_estimator_\n",
    "pred = tree_best.predict(X_test)\n",
    "print('Accuracy', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rules = export_text(tree_best, feature_names=X.columns)\n",
    "print(rules)\n",
    "print()\n",
    "print(\"Feature importance:\\n\")\n",
    "feature_importance = {}\n",
    "i = 0\n",
    "for col in X.columns:\n",
    "    feature_importance[col] = tree_best.feature_importances_[i]\n",
    "    i += 1\n",
    "features_sorted = sorted(feature_importance.items(), key=lambda x : x[1])\n",
    "features_sorted.reverse()\n",
    "for feature in features_sorted:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "text = tree.plot_tree(tree_best, \n",
    "                   feature_names=X.columns.to_list(), \n",
    "                   filled=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe try pre pruning with lower maximum height of tree, although that probably won't lead to better results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "params = {'max_depth':np.arange(3,15),\n",
    "#          'min_samples_leaf':[3,5,10,15,20],\n",
    "#          'min_samples_split':[8,10,12,18,20,16],\n",
    "          'criterion':['gini','entropy']}\n",
    "gs = GridSearchCV(cls, params, scoring='accuracy', cv=10, verbose=3, n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "params_optimal = gs.best_params_\n",
    "\n",
    "print(\"Best Score: %f\" % gs.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_best = DecisionTreeClassifier(random_state=0, criterion='entropy', max_depth=11) #, min_samples_leaf=20, min_samples_split=8)\n",
    "tree_best.fit(X_train, y_train)\n",
    "pred = tree_best.predict(X_test)\n",
    "\n",
    "print('Test accuracy',accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "text = tree.plot_tree(tree_best, \n",
    "                   feature_names=X.columns.to_list(), \n",
    "                   filled=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also try reduction of dimensions with PCA (only first 30 or so dimensions?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 KNN\n",
    "Lisa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter combinations for hyperparameter tuning via cross validation \n",
    "params = {'n_neighbors': np.arange(1,40),               # parameter k \n",
    "              'weights': ['uniform', 'distance'],       # parameter weights\n",
    "              'metric' : ['euclidean','manhattan']}     # parameter metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "# Use GridSearchCV to tune multiple parameters\n",
    "gs = GridSearchCV(knn, params, scoring='accuracy', cv=10, verbose=3, n_jobs=-1, refit=True)\n",
    "# Train\n",
    "gs.fit(X_train_mms, y_train_mms)    # Use training data scaled with MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_optimal = gs.best_params_\n",
    "\n",
    "print(\"Best score: %f\" % gs.best_score_)\n",
    "print(\"Optimal hyperparameters: \", params_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose optimal classifier to predict\n",
    "knn_optimal = gs.best_estimator_\n",
    "y_pred = knn_optimal.predict(X_test_mms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy for tuned KNN\n",
    "accuracy = accuracy_score(y_test_mms, y_pred)\n",
    "print('Accuracy:', accuracy)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparing Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC + ROC \n",
    "Accuracy summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Handle NaN values\n",
    "X_train_mms = X_train_mms.fillna(X_train_mms.mean())\n",
    "X_test_mms = X_test_mms.fillna(X_test_mms.mean())\n",
    "\n",
    "# Binarize the output\n",
    "y_test_bin = label_binarize(y_test_mms, classes=np.unique(y))\n",
    "y_train_bin = label_binarize(y_train_mms, classes=np.unique(y))\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "colors = ['red', 'blue', 'green']\n",
    "linestyles = ['-', '--', '-.']\n",
    "classifiers = [knn_optimal, tree_best, grid_search_rf.best_estimator_]\n",
    "labels = ['KNN', 'Decision Trees', 'Random Forest']\n",
    "\n",
    "for clf, label, clr, ls in zip(classifiers, labels, colors, linestyles):\n",
    "    classifier = OneVsRestClassifier(clf)\n",
    "    y_score = classifier.fit(X_train_mms, y_train_bin).predict_proba(X_test_mms)    \n",
    "    # Compute micro-average ROC curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin.ravel(), y_score.ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot the micro-average ROC curve\n",
    "    plt.plot(fpr, tpr, color=clr, linestyle=ls, label='%s (AUC = %0.2f)' % (label, roc_auc))\n",
    "\n",
    "# Add a diagonal line for reference\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', linewidth=2)\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.grid()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/roc.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. OPTIONAL: Song import and classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. References "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
