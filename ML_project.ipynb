{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Classification using multiple classifiers\n",
    "Team Members: Lisa Korntheuer, Jan Birkert, Adrian Desiderato, Jan Wangerin, Spyridon Spyropoulos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Data understanding\n",
    "Data describe (Features, Target etc.)\n",
    "- filename and length irrelevant for ML\n",
    "- 57 features -> PCA?\n",
    "- only numerical data except for class labels (\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/features_30_sec.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations between features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = df.iloc[:, 2:-2].corr()\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "ax = sns.heatmap(cor, square = True, xticklabels=True, yticklabels=True) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are quite a few feature combinations with high correlations, PCA may be worth a try. (See Data Prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "Jan W.\n",
    "\n",
    "Data splitting\n",
    "\n",
    "y = LabelEncoder() \n",
    "\n",
    "MinMax()\n",
    "Das andere() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabelEnc = LabelEncoder()\n",
    "y = df['label']\n",
    "y = pd.DataFrame(LabelEnc.fit_transform(y))\n",
    "df['label_enc'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_mms = MinMaxScaler()\n",
    "scaler_ss = StandardScaler()\n",
    "X = df.loc[:, 'chroma_stft_mean' : 'mfcc20_var']\n",
    "X_scaled_array_mms = scaler_mms.fit_transform(X)\n",
    "X_scaled_array_ss = scaler_ss.fit_transform(X)\n",
    "X_scaled_mms = pd.DataFrame(X_scaled_array_mms, columns=X.columns)\n",
    "X_scaled_ss = pd.DataFrame(X_scaled_array_ss, columns=X.columns)\n",
    "print(X)\n",
    "print(X_scaled_mms)\n",
    "print(X_scaled_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA: (copied from Material Notebook 04, probably has to be adjusted later on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA() # typically you add here as a parameter the nbr. of cmponents: i.e.: n_components=2\n",
    "            # we leave it blank to get all!\n",
    "pcs = pca.fit_transform(X_scaled_ss) # principle components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenvalues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pca.explained_variance_)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Principal Components (Dot Product of Data and Eigenvectors):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pcs[:5])\n",
    "print()\n",
    "print(len(pcs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scree Plot with Kaiser Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "pc_values = np.arange(pca.n_components_) + 1\n",
    "ax.plot(pc_values, pca.explained_variance_, 'o-', linewidth=2, color='blue')\n",
    "ax.xaxis.set_major_locator(ticker.MaxNLocator(integer=True))\n",
    "\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.axhline(y=1, linewidth=1, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potentially, a lot of dimensions could be removed according to the Kaiser criteria. The following enumeration shows how much \"information\" is contained in how many of the principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [10, 15, 30, 45]:\n",
    "    print(np.sum(pca.explained_variance_ratio_[:i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fight the curse of dimensionality, some dimensions could be removed, for example the last 12 to even 27 dimensions, since about 94% of \"information\" is contained in the first 30 PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "X_train_mms, X_test_mms, y_train_mms, y_test_mms = train_test_split(X_scaled_mms, y, test_size=0.2, random_state=0, stratify=y)\n",
    "X_train_ss, X_test_ss, y_train_ss, y_test_ss = train_test_split(X_scaled_ss, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model training \n",
    "\n",
    "Each Modell is trained and the quality of the classifier(accuracy) is displayed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Random Forests\n",
    "Spyridon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.tree as tree\n",
    "\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "rf_mms = RandomForestClassifier(random_state=0)\n",
    "rf_mms.fit(X_train_mms, y_train_mms.values.ravel())\n",
    "rf_ss = RandomForestClassifier(random_state=0)\n",
    "rf_ss.fit(X_train_ss, y_train_ss.values.ravel())\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_mms = rf_mms.predict(X_test_mms)\n",
    "y_pred_ss = rf_ss.predict(X_test_ss)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_mms, y_pred_mms)}\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test_ss, y_pred_ss)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Decision trees\n",
    "\n",
    "Jan W.\n",
    "\n",
    "First try using post-pruning and the entire dataset. Post-pruning is done using hyperparameter-tuning with GridsearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn import tree\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0) #maybe use variable for random state so that all classifiers can be adjusted at the same time\n",
    "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(ccp_alphas[:-1], impurities[:-1], marker=\"o\", drawstyle=\"steps-post\")\n",
    "ax.set_xlabel(\"effective alpha\")\n",
    "ax.set_ylabel(\"total impurity of leaves\")\n",
    "ax.set_title(\"Total Impurity vs effective alpha for training set\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'ccp_alpha':ccp_alphas[:-1].tolist()}\n",
    "gs = GridSearchCV(DecisionTreeClassifier(random_state=0), parameters, cv=10, refit=True)\n",
    "gs.fit(X_train,y_train)\n",
    "tree_best = gs.best_estimator_\n",
    "pred = tree_best.predict(X_test)\n",
    "print('Accuracy', accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rules = export_text(tree_best, feature_names=X.columns)\n",
    "print(rules)\n",
    "print()\n",
    "print(\"Feature importance:\\n\")\n",
    "feature_importance = {}\n",
    "i = 0\n",
    "for col in X.columns:\n",
    "    feature_importance[col] = tree_best.feature_importances_[i]\n",
    "    i += 1\n",
    "features_sorted = sorted(feature_importance.items(), key=lambda x : x[1])\n",
    "features_sorted.reverse()\n",
    "for feature in features_sorted:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "text = tree.plot_tree(tree_best, \n",
    "                   feature_names=X.columns.to_list(), \n",
    "                   filled=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe try pre pruning with lower maximum height of tree, although that probably won't lead to better results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "params = {'max_depth':np.arange(3,15),\n",
    "#          'min_samples_leaf':[3,5,10,15,20],\n",
    "#          'min_samples_split':[8,10,12,18,20,16],\n",
    "          'criterion':['gini','entropy']}\n",
    "gs = GridSearchCV(cls, params, scoring='accuracy', cv=10, verbose=3, n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "params_optimal = gs.best_params_\n",
    "\n",
    "print(\"Best Score: %f\" % gs.best_score_)\n",
    "print(\"Optimal Hyperparameter Values: \", params_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_best = DecisionTreeClassifier(random_state=0, criterion='entropy', max_depth=11) #, min_samples_leaf=20, min_samples_split=8)\n",
    "tree_best.fit(X_train, y_train)\n",
    "pred = tree_best.predict(X_test)\n",
    "\n",
    "print('Test accuracy',accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "text = tree.plot_tree(tree_best, \n",
    "                   feature_names=X.columns.to_list(), \n",
    "                   filled=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also try reduction of dimensions with PCA (only first 30 or so dimensions?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 KNN\n",
    "Lisa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter combinations for hyperparameter tuning via cross validation \n",
    "params = {'n_neighbors': np.arange(1,40),               # parameter k \n",
    "              'weights': ['uniform', 'distance'],       # parameter weights\n",
    "              'metric' : ['euclidean','manhattan']}     # parameter metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "# Use GridSearchCV to tune multiple parameters\n",
    "gs = GridSearchCV(knn, params, scoring='accuracy', cv=10, verbose=3, n_jobs=-1, refit=True)\n",
    "# Train\n",
    "gs.fit(X_train_mms, y_train_mms)    # Use training data scaled with MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_optimal = gs.best_params_\n",
    "\n",
    "print(\"Best score: %f\" % gs.best_score_)\n",
    "print(\"Optimal hyperparameters: \", params_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose optimal classifier to predict\n",
    "knn_optimal = gs.best_estimator_\n",
    "y_pred = knn_optimal.predict(X_test_mms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy for tuned KNN\n",
    "accuracy = accuracy_score(y_test_mms, y_pred)\n",
    "print('Accuracy:', accuracy)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparing Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC + ROC \n",
    "Accuracy summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. OPTIONAL: Song import and classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. References "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
